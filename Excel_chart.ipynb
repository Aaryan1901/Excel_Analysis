{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f419a767-be95-42cf-88ee-040ae47552ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.chart import PieChart, Reference, BarChart\n",
    "from openpyxl.chart.series import DataPoint\n",
    "from openpyxl.drawing.fill import ColorChoice\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05c03d8-f623-4c68-9482-f5ef6186511d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.chart import PieChart, Reference, BarChart\n",
    "from openpyxl.chart.series import DataPoint\n",
    "from openpyxl.drawing.fill import ColorChoice\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def analyze_tv_programs(input_file, output_path):\n",
    "    \"\"\"\n",
    "    Analyze TV programs data and generate required metrics\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Read the Excel file\n",
    "        print(\"Reading Excel file...\")\n",
    "        df = pd.read_excel(input_file)\n",
    "        \n",
    "        # Clean column names (remove any extra spaces)\n",
    "        df.columns = df.columns.str.strip()\n",
    "        \n",
    "        # Display basic info about the dataset\n",
    "        print(f\"Dataset shape: {df.shape}\")\n",
    "        print(f\"Columns: {list(df.columns)}\")\n",
    "        \n",
    "        # Check for missing values in key columns\n",
    "        print(\"\\nChecking for missing values...\")\n",
    "        key_columns = ['series_name', 'airing_data', 'delivery_date']\n",
    "        for col in key_columns:\n",
    "            if col in df.columns:\n",
    "                missing_count = df[col].isna().sum()\n",
    "                print(f\"{col}: {missing_count} missing values\")\n",
    "        \n",
    "        # ============ PROGRAMS ANALYSIS ============\n",
    "        print(\"\\n=== PROGRAMS ANALYSIS ===\")\n",
    "        \n",
    "        # Total programs\n",
    "        total_programs = len(df)\n",
    "        print(f\"Total programs: {total_programs}\")\n",
    "        \n",
    "        # Delivered programs (assuming programs with delivery_date are delivered)\n",
    "        delivered_programs = df['delivery_date'].notna().sum()\n",
    "        print(f\"Delivered programs: {delivered_programs}\")\n",
    "        \n",
    "        # Remaining programs\n",
    "        remaining_programs = total_programs - delivered_programs\n",
    "        print(f\"Remaining programs: {remaining_programs}\")\n",
    "        \n",
    "        # ============ CHANNELS ANALYSIS ============\n",
    "        print(\"\\n=== CHANNELS ANALYSIS ===\")\n",
    "        \n",
    "        # Function to split channels from airing_data\n",
    "        def extract_channels(airing_data):\n",
    "            \"\"\"Extract individual channels from airing_data string\"\"\"\n",
    "            if pd.isna(airing_data):\n",
    "                return []\n",
    "            \n",
    "            # Convert to string and clean\n",
    "            airing_str = str(airing_data).strip()\n",
    "            \n",
    "            # Remove any extra spaces and normalize\n",
    "            airing_str = ' '.join(airing_str.split())\n",
    "            \n",
    "            # If it's empty after cleaning, return empty list\n",
    "            if not airing_str:\n",
    "                return []\n",
    "            \n",
    "            # Try different delimiters in order of preference\n",
    "            delimiters = [',', ';', '|', '/', '\\\\']\n",
    "            channels = [airing_str]  # Start with the whole string\n",
    "            \n",
    "            for delimiter in delimiters:\n",
    "                if delimiter in airing_str:\n",
    "                    channels = airing_str.split(delimiter)\n",
    "                    break\n",
    "            \n",
    "            # Clean each channel and filter out empty/invalid ones\n",
    "            cleaned_channels = []\n",
    "            for channel in channels:\n",
    "                channel = channel.strip()\n",
    "                # Filter out empty strings and very short strings that might be noise\n",
    "                if channel and len(channel) >= 2:\n",
    "                    # Remove any trailing/leading special characters\n",
    "                    channel = channel.strip('.,;|/\\\\()[]{}')\n",
    "                    if channel:\n",
    "                        cleaned_channels.append(channel)\n",
    "            \n",
    "            return cleaned_channels\n",
    "        \n",
    "        # Create a list to store individual channel records\n",
    "        channel_records = []\n",
    "        \n",
    "        print(\"Processing channels from airing_data...\")\n",
    "        for idx, row in df.iterrows():\n",
    "            channels = extract_channels(row['airing_data'])\n",
    "            \n",
    "            # If no channels found, skip this row for channel analysis\n",
    "            if not channels:\n",
    "                continue\n",
    "                \n",
    "            for channel in channels:\n",
    "                # Additional cleaning for channel names\n",
    "                channel = channel.strip().upper()  # Normalize to uppercase\n",
    "                \n",
    "                # Skip if channel is too short or contains only numbers/special chars\n",
    "                if len(channel) < 2 or channel.isdigit():\n",
    "                    continue\n",
    "                    \n",
    "                channel_record = {\n",
    "                    'channel': channel,\n",
    "                    'series_name': row['series_name'],\n",
    "                    'delivered': pd.notna(row['delivery_date']),\n",
    "                    'delivery_date': row['delivery_date'],\n",
    "                    'original_row': idx\n",
    "                }\n",
    "                channel_records.append(channel_record)\n",
    "        \n",
    "        # Create DataFrame from channel records\n",
    "        channels_df = pd.DataFrame(channel_records)\n",
    "        \n",
    "        if len(channels_df) > 0:\n",
    "            print(f\"Total channel-program combinations: {len(channels_df)}\")\n",
    "            \n",
    "            # Group by channel to get channel-level metrics\n",
    "            channel_summary = channels_df.groupby('channel').agg({\n",
    "                'delivered': ['count', 'sum'],\n",
    "                'series_name': 'nunique'\n",
    "            }).reset_index()\n",
    "            \n",
    "            # Flatten column names\n",
    "            channel_summary.columns = ['channel', 'total_programs', 'delivered_programs', 'unique_series']\n",
    "            \n",
    "            # Calculate completion percentage\n",
    "            channel_summary['completion_percentage'] = (\n",
    "                channel_summary['delivered_programs'] / channel_summary['total_programs'] * 100\n",
    "            ).round(2)\n",
    "            \n",
    "            # Filter out channels with very few programs (likely noise)\n",
    "            channel_summary = channel_summary[channel_summary['total_programs'] >= 1]\n",
    "            \n",
    "            # Channel metrics\n",
    "            total_channels = len(channel_summary)\n",
    "            completed_channels = (channel_summary['completion_percentage'] == 100.0).sum()\n",
    "            pending_channels = total_channels - completed_channels\n",
    "            \n",
    "            print(f\"Total unique channels: {total_channels}\")\n",
    "            print(f\"Completed channels (100%): {completed_channels}\")\n",
    "            print(f\"Pending channels: {pending_channels}\")\n",
    "            \n",
    "            # Focus analysis\n",
    "            near_completion = ((channel_summary['completion_percentage'] >= 90.0) & \n",
    "                             (channel_summary['completion_percentage'] < 100.0)).sum()\n",
    "            focus_needed = (channel_summary['completion_percentage'] < 90.0).sum()\n",
    "            \n",
    "            print(f\"Near completion (≥90%): {near_completion}\")\n",
    "            print(f\"Focus needed (<90%): {focus_needed}\")\n",
    "            \n",
    "            # Top 20 channels to focus on\n",
    "            focus_channels = channel_summary[\n",
    "                channel_summary['completion_percentage'] < 100.0\n",
    "            ].nsmallest(20, 'completion_percentage')\n",
    "            \n",
    "            print(f\"Next top channels to focus: {min(20, len(focus_channels))}\")\n",
    "            \n",
    "        else:\n",
    "            print(\"No valid channels found in airing_data\")\n",
    "            total_channels = 0\n",
    "            completed_channels = 0\n",
    "            pending_channels = 0\n",
    "            near_completion = 0\n",
    "            focus_needed = 0\n",
    "        \n",
    "        # ============ CREATE OUTPUT ============\n",
    "        print(\"\\n=== CREATING OUTPUT ===\")\n",
    "        \n",
    "        # Create results DataFrame\n",
    "        results_data = [\n",
    "            ['Programs', 'Total', total_programs],\n",
    "            ['Programs', 'Delivered', delivered_programs],\n",
    "            ['Programs', 'Remaining', remaining_programs],\n",
    "            ['Channels', 'Total', total_channels],\n",
    "            ['Channels', 'Completed', completed_channels],\n",
    "            ['Channels', 'Pending', pending_channels],\n",
    "            ['Focus', 'Near-Completion (≥90 %)', near_completion],\n",
    "            ['Focus', 'Focus (<90 %)', focus_needed],\n",
    "            ['Focus', 'Next Top Channels to focus', min(20, len(focus_channels) if 'focus_channels' in locals() else 0)]\n",
    "        ]\n",
    "        \n",
    "        results_df = pd.DataFrame(results_data, columns=['Section', 'Metric', 'Value'])\n",
    "        \n",
    "        # Create output directory if it doesn't exist\n",
    "        os.makedirs(output_path, exist_ok=True)\n",
    "        \n",
    "        # Save main results\n",
    "        output_file = os.path.join(output_path, 'analysis_results.xlsx')\n",
    "        \n",
    "        # First save with pandas\n",
    "        with pd.ExcelWriter(output_file, engine='openpyxl') as writer:\n",
    "            # Main results\n",
    "            results_df.to_excel(writer, sheet_name='Summary', index=False)\n",
    "            \n",
    "            # Detailed channel analysis (if available)\n",
    "            if len(channels_df) > 0:\n",
    "                channel_summary_sorted = channel_summary.sort_values('completion_percentage')\n",
    "                channel_summary_sorted.to_excel(writer, sheet_name='Channel_Details', index=False)\n",
    "                \n",
    "                # Top channels to focus\n",
    "                if len(focus_channels) > 0:\n",
    "                    focus_channels_output = focus_channels[['channel', 'total_programs', 'delivered_programs', 'completion_percentage']].copy()\n",
    "                    focus_channels_output = focus_channels_output.sort_values('completion_percentage')\n",
    "                    focus_channels_output.to_excel(writer, sheet_name='Focus_Channels', index=False)\n",
    "            \n",
    "            # Original data sample\n",
    "            df.head(100).to_excel(writer, sheet_name='Original_Data_Sample', index=False)\n",
    "        \n",
    "        # Now add charts using openpyxl\n",
    "        print(\"Adding charts to Excel file...\")\n",
    "        try:\n",
    "            # Load the workbook\n",
    "            wb = load_workbook(output_file)\n",
    "            ws = wb['Summary']\n",
    "            \n",
    "            # Create chart data for donut chart\n",
    "            chart_data = [\n",
    "                ['Status', 'Count'],\n",
    "                ['Remaining', remaining_programs],\n",
    "                ['Delivered', delivered_programs]\n",
    "            ]\n",
    "            \n",
    "            # Add chart data to the worksheet starting from column E\n",
    "            for row_idx, row_data in enumerate(chart_data, start=1):\n",
    "                for col_idx, value in enumerate(row_data, start=5):  # Column E = 5\n",
    "                    ws.cell(row=row_idx, column=col_idx, value=value)\n",
    "            \n",
    "            # Create donut chart (which is a pie chart with a hole)\n",
    "            donut_chart = PieChart()\n",
    "            data = Reference(ws, min_col=6, min_row=2, max_row=3)  # Column F, rows 2-3\n",
    "            categories = Reference(ws, min_col=5, min_row=2, max_row=3)  # Column E, rows 2-3\n",
    "            \n",
    "            donut_chart.add_data(data)\n",
    "            donut_chart.set_categories(categories)\n",
    "            donut_chart.title = f\"{delivered_programs/total_programs*100:.1f}% Delivered\"\n",
    "            donut_chart.height = 10\n",
    "            donut_chart.width = 15\n",
    "            \n",
    "            # Make it a donut chart by setting the hole size\n",
    "            donut_chart.holeSize = 50  # Percentage of the hole size (10-90)\n",
    "            \n",
    "            # Customize colors using hex values directly\n",
    "            try:\n",
    "                # Blue for remaining (5B9BD5)\n",
    "                # Red for delivered (C65853)\n",
    "                colors = ['5B9BD5', 'C65853']\n",
    "                for i, color in enumerate(colors):\n",
    "                    props = DataPoint(idx=i)\n",
    "                    props.graphicalProperties.solidFill = color\n",
    "                    donut_chart.series[0].data_points = [props]\n",
    "            except Exception as e:\n",
    "                print(f\"Note: Could not set custom colors: {e}\")\n",
    "            \n",
    "            # Add chart to worksheet\n",
    "            ws.add_chart(donut_chart, \"H2\")\n",
    "            \n",
    "            # Add a second chart for completed channels if we have channel data\n",
    "            if len(channels_df) > 0:\n",
    "                # Get top 10 completed channels for horizontal bar chart\n",
    "                top_completed = channel_summary[channel_summary['completion_percentage'] == 100.0].nlargest(10, 'total_programs')\n",
    "                \n",
    "                if len(top_completed) > 0:\n",
    "                    # Add chart title and data starting from row 20\n",
    "                    ws.cell(row=20, column=5, value=\"Completed Channels (Total Records)\")\n",
    "                    \n",
    "                    # Add data for bar chart\n",
    "                    for idx, (_, row) in enumerate(top_completed.iterrows(), start=21):\n",
    "                        ws.cell(row=idx, column=5, value=row['channel'])\n",
    "                        ws.cell(row=idx, column=6, value=row['total_programs'])\n",
    "                    \n",
    "                    # Create horizontal bar chart\n",
    "                    bar_chart = BarChart()\n",
    "                    bar_chart.type = \"bar\"\n",
    "                    bar_chart.style = 10\n",
    "                    bar_chart.title = \"Completed Channels (Total Records)\"\n",
    "                    bar_chart.y_axis.title = 'Channels'\n",
    "                    bar_chart.x_axis.title = 'Total Programs'\n",
    "                    \n",
    "                    data = Reference(ws, min_col=6, min_row=21, max_row=20+len(top_completed))\n",
    "                    categories = Reference(ws, min_col=5, min_row=21, max_row=20+len(top_completed))\n",
    "                    \n",
    "                    bar_chart.add_data(data)\n",
    "                    bar_chart.set_categories(categories)\n",
    "                    bar_chart.height = 12\n",
    "                    bar_chart.width = 18\n",
    "                    ws.add_chart(bar_chart, \"H25\")\n",
    "            \n",
    "            # Save the workbook with charts\n",
    "            wb.save(output_file)\n",
    "            print(\"Charts added successfully!\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error adding charts: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "        \n",
    "        print(f\"\\nResults saved to: {output_file}\")\n",
    "        \n",
    "        # Display results\n",
    "        print(\"\\n=== FINAL RESULTS ===\")\n",
    "        print(results_df.to_string(index=False))\n",
    "        \n",
    "        # Additional insights\n",
    "        if len(channels_df) > 0:\n",
    "            print(f\"\\n=== ADDITIONAL INSIGHTS ===\")\n",
    "            print(f\"Average completion percentage: {channel_summary['completion_percentage'].mean():.2f}%\")\n",
    "            print(f\"Median completion percentage: {channel_summary['completion_percentage'].median():.2f}%\")\n",
    "            \n",
    "            # Show sample of channels and their completion rates\n",
    "            print(\"\\nSample of channel completion rates:\")\n",
    "            sample_channels = channel_summary.head(10)[['channel', 'total_programs', 'delivered_programs', 'completion_percentage']]\n",
    "            print(sample_channels.to_string(index=False))\n",
    "        \n",
    "        return results_df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # File paths\n",
    "    input_file = r\"C:\\Users\\Aaryan\\Documents\\combined\\combined.xlsx\"\n",
    "    output_path = r\"C:\\Users\\Aaryan\\Documents\\combined\\output\"\n",
    "    \n",
    "    # Check if input file exists\n",
    "    if not os.path.exists(input_file):\n",
    "        print(f\"Error: Input file not found at {input_file}\")\n",
    "        print(\"Please check the file path and try again.\")\n",
    "    else:\n",
    "        print(f\"Processing file: {input_file}\")\n",
    "        print(f\"Output will be saved to: {output_path}\")\n",
    "        \n",
    "        # Run analysis\n",
    "        results = analyze_tv_programs(input_file, output_path)\n",
    "        \n",
    "        if results is not None:\n",
    "            print(\"\\n✅ Analysis completed successfully!\")\n",
    "            print(f\"📊 Results saved to: {os.path.join(output_path, 'analysis_results.xlsx')}\")\n",
    "        else:\n",
    "            print(\"\\n❌ Analysis failed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5bd420-fb02-4c53-93ae-1a18fc98c178",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d7350c-fa33-4554-b7e8-bd1509f4efd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa53d3f3-8729-4b63-843a-aee6a001bb0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20902489-2f13-42ce-94b3-5f5f0a04c2d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09dd1483-93fb-4e3e-b4e8-15803b946787",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b498a8c-6da5-44fe-b842-30cc9509e743",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98cf29de-0e77-4346-871f-9467b86b3e42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bab1518-010b-4141-b4b6-a5874d951408",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8b6c3d-8e15-43f1-b827-784e51d63f5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eafdb39-6354-4e48-b506-271f1d65a010",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a84b2e2-8f81-4d67-b207-24f6faa2e41f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd92e859-1369-40f1-a04e-8eeb259b34d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6af36d-9f02-493e-af9b-27975139aa5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10013374-c6f6-4845-abf1-b1834a131561",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3ab3ef-954f-4562-ba34-e27ec4ff4c91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14af73b-9c54-481a-b70e-27bdecc6eeef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f55d732-0418-4fad-97a9-5bf8f439c260",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103e444b-c4a7-4633-bb2f-e0d5ca322abc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61d2703-d0e8-4d5c-bc57-8d15ebaac5fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb23173d-a6ad-49f6-a7b1-bcf582724cbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910fc4b4-0697-4b67-9e8d-6f65147cc069",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9884a509-9b9f-4736-b724-3a9e3c662946",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3f25d1-ab8e-4537-a0f3-d7219ec8e716",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906b61d9-910b-4b45-8a71-a20ff2ac48da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410de0c8-43a5-4e6b-adc1-16ed01083f00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b14a05b-219d-4c55-9e2a-6e6269f6cef6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006c6fcd-ff19-4cbe-bb2b-e649975bc0a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5194fc19-fefa-459f-964c-fecba6cc852c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5486d1b6-95bb-4d1d-b968-832cb0d0103f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95214b88-57b9-4124-bb71-0494cbbab8c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f74bbd6-cb58-42cb-8fa0-10e8aeeead3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de3993a-4704-4495-ab61-364ae80fc044",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6f9a0f-eb80-4e99-849e-69737df8d462",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6576daf-6c5a-4f27-9172-164a7c514365",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1115338f-30f4-426c-9809-448c53c99bef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995adb73-be7a-4662-a69c-c30887a025bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89688625-f3d7-4ff7-9ef5-a9a2afe196c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75b416d-0471-4d61-bdff-9e8dc9d2b337",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68dfb5e9-8c93-4737-99b0-3c59f1a5d76d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae17939-d2f4-417d-8c20-030e6bd1df3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a1b722-4c0a-4348-b6f4-2a14f67836f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e978f88-a1f5-45fa-89d3-aa487d00c386",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72a4ee6-f481-45cb-8777-f2e3ee1f6b41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d88408-e108-420a-a2f1-cece8d92502c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
